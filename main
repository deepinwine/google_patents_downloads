import os
import re
import asyncio
import requests
from bs4 import BeautifulSoup
from playwright.async_api import async_playwright
import openpyxl

# -------------------------
# 配置
# -------------------------
excel_file = "patents.xlsx"
output_dir = "patent_texts"
os.makedirs(output_dir, exist_ok=True)

wb = openpyxl.load_workbook(excel_file)
sheet = wb.active

# -------------------------
# 自动检测专利号列
# -------------------------
def detect_patent_col(sheet):
    for row in sheet.iter_rows(min_row=2, values_only=True):
        for i, cell in enumerate(row):
            if cell and isinstance(cell, str) and re.match(r"^(CN|US|EP|JP|KR)\d+", cell):
                print(f"✅ 自动检测到专利号列: 第 {i+1} 列")
                return i
    return 0

# -------------------------
# 分段落编号
# -------------------------
def split_paragraphs(text, title):
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    numbered = [f"[{i+1}] {line}" for i, line in enumerate(lines)]
    return f"=== {title} ===\n" + "\n".join(numbered)

# -------------------------
# 保存文本
# -------------------------
def save_text(patent_id, text):
    file_path = os.path.join(output_dir, f"{patent_id}.txt")
    clean_text = text.encode("utf-8", "ignore").decode("utf-8")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(clean_text)
    print(f"✅ 保存成功: {file_path}")

# -------------------------
# Google Patents 抓取
# -------------------------
def fetch_google(patent_id):
    langs = ["zh", "en"]
    for lang in langs:
        url = f"https://patents.google.com/patent/{patent_id}/{lang}"
        print(f"尝试 Google Patents: {url}")
        try:
            r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=20)
            r.encoding = "utf-8"  # 强制 UTF-8
        except Exception as e:
            print(f"⚠️ 请求失败: {e}")
            continue

        if r.status_code != 200:
            continue

        soup = BeautifulSoup(r.text, "html.parser")
        desc = soup.find("section", itemprop="description")
        claims = soup.find("section", itemprop="claims")

        if desc or claims:
            text = ""
            if desc:
                text += split_paragraphs(desc.get_text("\n", strip=True), "说明书") + "\n\n"
            if claims:
                text += split_paragraphs(claims.get_text("\n", strip=True), "权利要求") + "\n\n"
            return text
    return None

# -------------------------
# Zhihuiya 抓取
# -------------------------
async def fetch_zhihuiya(patent_id):
    url = f"https://search.zhihuiya.com/patent/{patent_id}"
    print(f"尝试 专利汇: {url}")
    text_parts = []
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        try:
            await page.goto(url, timeout=60000)
            await page.wait_for_timeout(3000)

            # 说明书
            try:
                await page.click("text=说明书", timeout=5000)
                await page.wait_for_selector("div.detail-content", timeout=10000)
                desc = await page.inner_text("div.detail-content")
                if desc.strip():
                    desc = desc.encode("utf-8", "ignore").decode("utf-8")  # 修复乱码
                    text_parts.append(split_paragraphs(desc, "说明书"))
            except:
                pass

            # 权利要求
            try:
                await page.click("text=权利要求", timeout=5000)
                await page.wait_for_selector("div.detail-content", timeout=10000)
                claims = await page.inner_text("div.detail-content")
                if claims.strip():
                    claims = claims.encode("utf-8", "ignore").decode("utf-8")
                    text_parts.append(split_paragraphs(claims, "权利要求"))
            except:
                pass
        except Exception as e:
            print(f"⚠️ Zhihuiya 页面访问失败: {e}")
        await browser.close()

    if text_parts:
        return "\n\n".join(text_parts)
    return None

# -------------------------
# CNIPA 兜底（仅提示）
# -------------------------
def fetch_cnipa(patent_id):
    print(f"⚠️ CNIPA 查询需要人工或 API 支持: {patent_id}")
    return None

# -------------------------
# 爬取单个专利
# -------------------------
async def fetch_patent(patent_id):
    text = fetch_google(patent_id)
    if not text:
        text = await fetch_zhihuiya(patent_id)
    if not text:
        text = fetch_cnipa(patent_id)

    if text:
        save_text(patent_id, text)
    else:
        print(f"❌ 未获取到: {patent_id}")

# -------------------------
# 主函数
# -------------------------
async def main():
    patent_col = detect_patent_col(sheet)
    tasks = []
    for row in sheet.iter_rows(min_row=2, values_only=True):
        patent_id = row[patent_col]
        if patent_id:
            tasks.append(fetch_patent(patent_id))
    await asyncio.gather(*tasks)

if __name__ == "__main__":
    asyncio.run(main())
